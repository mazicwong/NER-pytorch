{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cited from tutorial of pytorch: https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 5\n",
    "HIDDEN_DIM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make up some training data\n",
    "training_data = [(\n",
    "    \"the wall street journal reported today that apple corporation made money\".split(),\n",
    "    \"B I I I O O O B I O O\".split()\n",
    "), (\n",
    "    \"georgia tech is a university in georgia\".split(),\n",
    "    \"B I O O O O B\".split()\n",
    ")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"the\": 0,\n",
      "  \"wall\": 1,\n",
      "  \"street\": 2,\n",
      "  \"journal\": 3,\n",
      "  \"reported\": 4,\n",
      "  \"today\": 5,\n",
      "  \"that\": 6,\n",
      "  \"apple\": 7,\n",
      "  \"corporation\": 8,\n",
      "  \"made\": 9,\n",
      "  \"money\": 10,\n",
      "  \"georgia\": 11,\n",
      "  \"tech\": 12,\n",
      "  \"is\": 13,\n",
      "  \"a\": 14,\n",
      "  \"university\": 15,\n",
      "  \"in\": 16\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {}                                                                                                                                                                                        \n",
    "for sentence, tags in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "import json\n",
    "print(json.dumps(word_to_ix, indent=2, ensure_ascii=False))\n",
    "\n",
    "# tag_dict\n",
    "tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n",
    "id_to_tag = {0:\"B\", 1:\"I\", 2:\"O\", 3: START_TAG, 4:STOP_TAG}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(14.0426), [2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n",
      "(tensor(14.8678), [2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "from BiLSTM_CRF import BiLSTM_CRF\n",
    "from BiLSTM_CRF import argmax,prepare_sequence,log_sum_exp\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM) # (11, tag_dict, 5, 4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "# Check predictions before training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
    "    print(model(precheck_sent))\n",
    "    print(model(precheck_tags))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2])\n",
      "['the', 'wall', 'street', 'journal', 'reported', 'today', 'that', 'apple', 'corporation', 'made', 'money']\n"
     ]
    }
   ],
   "source": [
    "print(precheck_sent)\n",
    "print(precheck_tags)\n",
    "print(training_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
    "for epoch in range(                                                                                                                                                                                    \n",
    "        300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad() # 为什么这里不是optimizer.zero_grad()  ; 解决: 这里model.zero_grad()跟optimizer.zero_grad()是等价的\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(34.3337), [0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    print(model(precheck_sent))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
